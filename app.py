"""
VisionTrack: Real-Time Object Detection & Tracking
Built for Streamlit Cloud â€” Python 3.11 / 3.13 compatible
"""

import streamlit as st
import cv2
import numpy as np
import time
from PIL import Image
import tempfile
import os
from collections import defaultdict

# ============================================================================
# CONFIGURATION
# ============================================================================

CONFIDENCE_THRESHOLD = 0.5
IOU_THRESHOLD = 0.45
INPUT_SIZE = 640

COCO_CLASSES = [
    'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat',
    'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat',
    'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack',
    'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball',
    'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket',
    'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple',
    'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair',
    'couch', 'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse',
    'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator',
    'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush'
]


# ============================================================================
# OBJECT DETECTOR (YOLOv8)
# ============================================================================

class ObjectDetector:
    """YOLOv8-based object detector."""

    def __init__(self, conf_threshold=None, input_size=None):
        self.conf_threshold = conf_threshold or CONFIDENCE_THRESHOLD
        self.input_size = input_size or INPUT_SIZE
        self.model = None
        self.fps = 0.0
        self.frame_count = 0
        self.start_time = time.time()

    def load(self):
        if self.model is not None:
            return
        from ultralytics import YOLO
        self.model = YOLO('yolov8n.pt')
        self.model.overrides['conf'] = self.conf_threshold
        self.model.overrides['iou'] = IOU_THRESHOLD

    def detect(self, frame):
        if self.model is None:
            self.load()

        results = self.model(
            frame,
            imgsz=self.input_size,
            conf=self.conf_threshold,
            verbose=False
        )

        detections = []
        if len(results) > 0 and results[0].boxes is not None:
            for box in results[0].boxes:
                x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()
                conf = float(box.conf[0].cpu().numpy())
                cls = int(box.cls[0].cpu().numpy())
                detections.append([x1, y1, x2, y2, conf, cls])

        self._update_fps()
        return np.array(detections) if detections else np.empty((0, 6))

    def _update_fps(self):
        self.frame_count += 1
        elapsed = time.time() - self.start_time
        if elapsed > 0:
            self.fps = self.frame_count / elapsed
        if self.frame_count >= 30:
            self.frame_count = 0
            self.start_time = time.time()

    @staticmethod
    def get_class_name(class_id):
        if 0 <= class_id < len(COCO_CLASSES):
            return COCO_CLASSES[class_id]
        return f"class_{class_id}"


# ============================================================================
# MULTI-OBJECT TRACKER (IOU-based, zero external deps)
# ============================================================================

class SimpleTracker:
    """Lightweight IOU-based multi-object tracker. No external dependencies."""

    def __init__(self, max_disappeared=30, iou_threshold=0.3):
        self.next_id = 1
        self.objects = {}
        self.track_history = {}
        self.max_disappeared = max_disappeared
        self.iou_threshold = iou_threshold
        self.total_tracks = 0

    @staticmethod
    def _iou(box_a, box_b):
        x1 = max(box_a[0], box_b[0])
        y1 = max(box_a[1], box_b[1])
        x2 = min(box_a[2], box_b[2])
        y2 = min(box_a[3], box_b[3])
        inter = max(0, x2 - x1) * max(0, y2 - y1)
        area_a = (box_a[2] - box_a[0]) * (box_a[3] - box_a[1])
        area_b = (box_b[2] - box_b[0]) * (box_b[3] - box_b[1])
        union = area_a + area_b - inter
        return inter / union if union > 0 else 0

    def update(self, detections):
        if len(detections) == 0:
            for obj_id in list(self.objects):
                self.objects[obj_id]['disappeared'] += 1
                if self.objects[obj_id]['disappeared'] > self.max_disappeared:
                    del self.objects[obj_id]
            return []

        det_boxes = detections[:, :4]
        det_confs = detections[:, 4]
        det_classes = detections[:, 5].astype(int)

        if len(self.objects) == 0:
            for i in range(len(detections)):
                self._register(det_boxes[i], det_classes[i], det_confs[i])
        else:
            obj_ids = list(self.objects.keys())
            obj_boxes = np.array([self.objects[oid]['bbox'] for oid in obj_ids])

            iou_matrix = np.zeros((len(obj_ids), len(det_boxes)))
            for i, ob in enumerate(obj_boxes):
                for j, db in enumerate(det_boxes):
                    iou_matrix[i, j] = self._iou(ob, db)

            matched_objs = set()
            matched_dets = set()

            while True:
                if iou_matrix.size == 0:
                    break
                max_val = iou_matrix.max()
                if max_val < self.iou_threshold:
                    break
                max_idx = np.unravel_index(iou_matrix.argmax(), iou_matrix.shape)
                i, j = max_idx

                oid = obj_ids[i]
                self.objects[oid]['bbox'] = det_boxes[j]
                self.objects[oid]['class_id'] = det_classes[j]
                self.objects[oid]['conf'] = det_confs[j]
                self.objects[oid]['disappeared'] = 0

                cx = int((det_boxes[j][0] + det_boxes[j][2]) / 2)
                cy = int((det_boxes[j][1] + det_boxes[j][3]) / 2)
                self.track_history[oid].append((cx, cy))
                if len(self.track_history[oid]) > 30:
                    self.track_history[oid] = self.track_history[oid][-30:]

                matched_objs.add(i)
                matched_dets.add(j)
                iou_matrix[i, :] = 0
                iou_matrix[:, j] = 0

            for i, oid in enumerate(obj_ids):
                if i not in matched_objs:
                    self.objects[oid]['disappeared'] += 1
                    if self.objects[oid]['disappeared'] > self.max_disappeared:
                        del self.objects[oid]

            for j in range(len(det_boxes)):
                if j not in matched_dets:
                    self._register(det_boxes[j], det_classes[j], det_confs[j])

        tracked = []
        for oid, obj in self.objects.items():
            if obj['disappeared'] == 0:
                b = obj['bbox']
                tracked.append([b[0], b[1], b[2], b[3], oid, obj['class_id'], obj['conf']])
        return tracked

    def _register(self, bbox, class_id, conf):
        oid = self.next_id
        self.next_id += 1
        self.total_tracks += 1
        cx = int((bbox[0] + bbox[2]) / 2)
        cy = int((bbox[1] + bbox[3]) / 2)
        self.objects[oid] = {
            'bbox': bbox, 'class_id': int(class_id),
            'conf': float(conf), 'disappeared': 0,
        }
        self.track_history[oid] = [(cx, cy)]

    @property
    def active_tracks(self):
        return sum(1 for o in self.objects.values() if o['disappeared'] == 0)


# ============================================================================
# VISUALIZER
# ============================================================================

class Visualizer:
    def __init__(self):
        np.random.seed(42)
        self.colors = self._generate_colors(100)

    @staticmethod
    def _generate_colors(n):
        colors = []
        for i in range(n):
            hue = int(180 * i / n)
            color = cv2.cvtColor(np.uint8([[[hue, 255, 200]]]), cv2.COLOR_HSV2BGR)[0][0]
            colors.append(tuple(map(int, color)))
        return colors

    def draw_detections(self, frame, detections):
        out = frame.copy()
        for det in detections:
            x1, y1, x2, y2, conf, cls = det
            x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)
            color = self.colors[int(cls) % len(self.colors)]
            label = f"{ObjectDetector.get_class_name(int(cls))} {conf:.2f}"
            cv2.rectangle(out, (x1, y1), (x2, y2), color, 2)
            (lw, lh), _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.55, 1)
            cv2.rectangle(out, (x1, y1 - lh - 8), (x1 + lw + 4, y1), color, -1)
            cv2.putText(out, label, (x1 + 2, y1 - 4), cv2.FONT_HERSHEY_SIMPLEX, 0.55, (255, 255, 255), 1, cv2.LINE_AA)
        return out

    def draw_tracks(self, frame, tracked_objects, track_history, show_trails=True):
        out = frame.copy()
        for obj in tracked_objects:
            x1, y1, x2, y2, tid, cls, conf = obj
            x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)
            color = self.colors[int(tid) % len(self.colors)]
            label = f"ID:{tid} {ObjectDetector.get_class_name(int(cls))} {conf:.2f}"
            cv2.rectangle(out, (x1, y1), (x2, y2), color, 2)
            (lw, lh), _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.55, 1)
            cv2.rectangle(out, (x1, y1 - lh - 8), (x1 + lw + 4, y1), color, -1)
            cv2.putText(out, label, (x1 + 2, y1 - 4), cv2.FONT_HERSHEY_SIMPLEX, 0.55, (255, 255, 255), 1, cv2.LINE_AA)
            if show_trails and tid in track_history and len(track_history[tid]) > 1:
                pts = track_history[tid]
                for k in range(1, len(pts)):
                    thickness = max(1, int(np.sqrt(40 / float(k + 1)) * 1.2))
                    cv2.line(out, pts[k - 1], pts[k], color, thickness, cv2.LINE_AA)
        return out

    @staticmethod
    def draw_overlay(frame, fps, det_count, track_count):
        overlay = frame.copy()
        cv2.rectangle(overlay, (8, 8), (220, 120), (15, 15, 25), -1)
        frame = cv2.addWeighted(overlay, 0.7, frame, 0.3, 0)
        cv2.rectangle(frame, (8, 8), (220, 120), (124, 58, 237), 2)
        cv2.putText(frame, f"FPS: {fps:.1f}", (18, 35), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (124, 58, 237), 2, cv2.LINE_AA)
        cv2.putText(frame, f"Detections: {det_count}", (18, 65), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (16, 185, 129), 2, cv2.LINE_AA)
        cv2.putText(frame, f"Tracks: {track_count}", (18, 95), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (59, 130, 246), 2, cv2.LINE_AA)
        return frame


# ============================================================================
# CUSTOM CSS
# ============================================================================

CUSTOM_CSS = """
<style>
@import url('https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap');

html, body, [class*="css"] { font-family: 'Inter', sans-serif; }

.main-header {
    background: linear-gradient(135deg, #7C3AED 0%, #EC4899 100%);
    -webkit-background-clip: text; -webkit-text-fill-color: transparent;
    font-size: 2.8rem; font-weight: 700; text-align: center;
    margin-bottom: 0; line-height: 1.2;
}
.sub-header {
    text-align: center; color: #9CA3AF; font-size: 1.05rem;
    margin-top: -0.5rem; margin-bottom: 1.5rem;
}

.metric-card {
    background: linear-gradient(145deg, #1E1E2E 0%, #2A2A3E 100%);
    border: 1px solid rgba(124, 58, 237, 0.3); border-radius: 12px;
    padding: 1.2rem 1rem; text-align: center;
    transition: transform 0.2s, box-shadow 0.2s;
}
.metric-card:hover {
    transform: translateY(-2px);
    box-shadow: 0 8px 25px rgba(124, 58, 237, 0.2);
}
.metric-value {
    font-size: 2rem; font-weight: 700;
    background: linear-gradient(135deg, #7C3AED 0%, #3B82F6 100%);
    -webkit-background-clip: text; -webkit-text-fill-color: transparent;
}
.metric-label { font-size: 0.85rem; color: #9CA3AF; margin-top: 0.25rem; }

section[data-testid="stSidebar"] {
    background: linear-gradient(180deg, #0F0F1A 0%, #1A1A2E 100%);
    border-right: 1px solid rgba(124, 58, 237, 0.2);
}

.stTabs [data-baseweb="tab-list"] { gap: 8px; }
.stTabs [data-baseweb="tab"] { border-radius: 8px; padding: 8px 20px; }

.feature-card {
    background: linear-gradient(145deg, #1E1E2E 0%, #252540 100%);
    border: 1px solid rgba(124, 58, 237, 0.15); border-radius: 12px;
    padding: 1.5rem; height: 100%;
}
.feature-card h4 { color: #A78BFA; margin-bottom: 0.5rem; }

.tech-badge {
    display: inline-block; background: rgba(124, 58, 237, 0.15);
    border: 1px solid rgba(124, 58, 237, 0.3); border-radius: 20px;
    padding: 0.3rem 0.9rem; margin: 0.2rem; font-size: 0.85rem; color: #A78BFA;
}
.footer {
    text-align: center; color: #6B7280; font-size: 0.85rem;
    margin-top: 3rem; padding: 1rem 0;
    border-top: 1px solid rgba(124, 58, 237, 0.15);
}
</style>
"""


# ============================================================================
# HELPER: process a video completely and show results
# ============================================================================

def process_video(video_path, detector, viz, conf_threshold, input_size,
                  enable_tracking, show_trails, show_overlay,
                  video_placeholder, fps_ph, det_ph, trk_ph, frm_ph,
                  status_placeholder, progress_bar):
    """Process the entire video file, streaming frames into the Streamlit UI."""

    detector.conf_threshold = conf_threshold
    detector.input_size = input_size

    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened():
        status_placeholder.error("âŒ Could not open video file.")
        return []

    status_placeholder.info("â³ Loading YOLOv8 model... (first run downloads ~6 MB)")
    detector.load()
    status_placeholder.empty()

    tracker_inst = SimpleTracker()
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT)) or 1
    frame_idx = 0
    detection_log = []

    while cap.isOpened():
        ret, frame = cap.read()
        if not ret:
            break
        frame_idx += 1

        # Resize for speed
        h, w = frame.shape[:2]
        if w > 800:
            scale = 800 / w
            frame = cv2.resize(frame, None, fx=scale, fy=scale)

        # Detect
        dets = detector.detect(frame)

        # Track
        if enable_tracking:
            tracked = tracker_inst.update(dets)
            annotated = viz.draw_tracks(frame, tracked, tracker_inst.track_history, show_trails)
            active_trk = tracker_inst.active_tracks
        else:
            annotated = viz.draw_detections(frame, dets)
            active_trk = 0

        # Overlay
        if show_overlay:
            annotated = Visualizer.draw_overlay(annotated, detector.fps, len(dets), active_trk)

        # Show frame
        annotated_rgb = cv2.cvtColor(annotated, cv2.COLOR_BGR2RGB)
        video_placeholder.image(annotated_rgb, use_container_width=True)

        # Progress
        progress_bar.progress(min(frame_idx / total_frames, 1.0),
                              text=f"Processing frame {frame_idx}/{total_frames}")

        # Metrics
        fps_ph.markdown(f'<div class="metric-card"><div class="metric-value">{detector.fps:.1f}</div><div class="metric-label">FPS</div></div>', unsafe_allow_html=True)
        det_ph.markdown(f'<div class="metric-card"><div class="metric-value">{len(dets)}</div><div class="metric-label">Detections</div></div>', unsafe_allow_html=True)
        trk_ph.markdown(f'<div class="metric-card"><div class="metric-value">{active_trk}</div><div class="metric-label">Active Tracks</div></div>', unsafe_allow_html=True)
        frm_ph.markdown(f'<div class="metric-card"><div class="metric-value">{frame_idx}</div><div class="metric-label">Frame</div></div>', unsafe_allow_html=True)

        detection_log.append({
            'frame': frame_idx, 'detections': len(dets),
            'tracks': active_trk, 'fps': round(detector.fps, 1),
        })

    cap.release()
    progress_bar.empty()
    return detection_log


def process_webcam(detector, viz, conf_threshold, input_size,
                   enable_tracking, show_trails, show_overlay,
                   video_placeholder, fps_ph, det_ph, trk_ph, frm_ph,
                   status_placeholder, stop_container):
    """Process live webcam feed."""

    detector.conf_threshold = conf_threshold
    detector.input_size = input_size

    cap = cv2.VideoCapture(0)
    if not cap.isOpened():
        status_placeholder.error("âŒ Could not open webcam. Make sure a camera is connected and permissions are granted.")
        return []

    status_placeholder.info("â³ Loading YOLOv8 model... (first run downloads ~6 MB)")
    detector.load()
    status_placeholder.empty()

    tracker_inst = SimpleTracker()
    frame_idx = 0
    detection_log = []

    # Use a callback-based stop mechanism
    stop_pressed = stop_container.button("â¹ Stop Webcam", use_container_width=True, type="secondary", key="stop_webcam_btn")

    while cap.isOpened():
        ret, frame = cap.read()
        if not ret:
            status_placeholder.warning("âš ï¸ Lost webcam feed.")
            break
        frame_idx += 1

        h, w = frame.shape[:2]
        if w > 800:
            scale = 800 / w
            frame = cv2.resize(frame, None, fx=scale, fy=scale)

        dets = detector.detect(frame)

        if enable_tracking:
            tracked = tracker_inst.update(dets)
            annotated = viz.draw_tracks(frame, tracked, tracker_inst.track_history, show_trails)
            active_trk = tracker_inst.active_tracks
        else:
            annotated = viz.draw_detections(frame, dets)
            active_trk = 0

        if show_overlay:
            annotated = Visualizer.draw_overlay(annotated, detector.fps, len(dets), active_trk)

        annotated_rgb = cv2.cvtColor(annotated, cv2.COLOR_BGR2RGB)
        video_placeholder.image(annotated_rgb, use_container_width=True)

        fps_ph.markdown(f'<div class="metric-card"><div class="metric-value">{detector.fps:.1f}</div><div class="metric-label">FPS</div></div>', unsafe_allow_html=True)
        det_ph.markdown(f'<div class="metric-card"><div class="metric-value">{len(dets)}</div><div class="metric-label">Detections</div></div>', unsafe_allow_html=True)
        trk_ph.markdown(f'<div class="metric-card"><div class="metric-value">{active_trk}</div><div class="metric-label">Active Tracks</div></div>', unsafe_allow_html=True)
        frm_ph.markdown(f'<div class="metric-card"><div class="metric-value">{frame_idx}</div><div class="metric-label">Frame</div></div>', unsafe_allow_html=True)

        detection_log.append({
            'frame': frame_idx, 'detections': len(dets),
            'tracks': active_trk, 'fps': round(detector.fps, 1),
        })

        # Check if user wants to stop (Streamlit re-runs on button click)
        if stop_pressed:
            break

    cap.release()
    return detection_log


def process_image(image_file, detector, viz, conf_threshold, input_size,
                  enable_tracking, show_overlay,
                  video_placeholder, fps_ph, det_ph, trk_ph, frm_ph):
    """Process a single uploaded image."""

    detector.conf_threshold = conf_threshold
    detector.input_size = input_size
    detector.load()

    img = Image.open(image_file)
    frame = np.array(img)

    # Convert RGB to BGR for OpenCV
    if len(frame.shape) == 3 and frame.shape[2] == 3:
        frame_bgr = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)
    else:
        frame_bgr = frame

    h, w = frame_bgr.shape[:2]
    if w > 1200:
        scale = 1200 / w
        frame_bgr = cv2.resize(frame_bgr, None, fx=scale, fy=scale)

    dets = detector.detect(frame_bgr)

    if enable_tracking:
        tracker_inst = SimpleTracker()
        tracked = tracker_inst.update(dets)
        annotated = viz.draw_tracks(frame_bgr, tracked, tracker_inst.track_history, False)
        active_trk = tracker_inst.active_tracks
    else:
        annotated = viz.draw_detections(frame_bgr, dets)
        active_trk = 0

    if show_overlay:
        annotated = Visualizer.draw_overlay(annotated, detector.fps, len(dets), active_trk)

    annotated_rgb = cv2.cvtColor(annotated, cv2.COLOR_BGR2RGB)
    video_placeholder.image(annotated_rgb, use_container_width=True)

    fps_ph.markdown(f'<div class="metric-card"><div class="metric-value">{detector.fps:.1f}</div><div class="metric-label">FPS</div></div>', unsafe_allow_html=True)
    det_ph.markdown(f'<div class="metric-card"><div class="metric-value">{len(dets)}</div><div class="metric-label">Detections</div></div>', unsafe_allow_html=True)
    trk_ph.markdown(f'<div class="metric-card"><div class="metric-value">{active_trk}</div><div class="metric-label">Active Tracks</div></div>', unsafe_allow_html=True)
    frm_ph.markdown(f'<div class="metric-card"><div class="metric-value">1</div><div class="metric-label">Frame</div></div>', unsafe_allow_html=True)

    return [{'frame': 1, 'detections': len(dets), 'tracks': active_trk, 'fps': round(detector.fps, 1)}]


# ============================================================================
# STREAMLIT APP
# ============================================================================

def main():
    st.set_page_config(
        page_title="VisionTrack â€” Object Detection & Tracking",
        page_icon="ğŸ¯",
        layout="wide",
        initial_sidebar_state="expanded",
    )

    st.markdown(CUSTOM_CSS, unsafe_allow_html=True)

    # â”€â”€ Session State â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    if 'detector' not in st.session_state:
        st.session_state.detector = ObjectDetector()
    if 'visualizer' not in st.session_state:
        st.session_state.visualizer = Visualizer()
    if 'detection_log' not in st.session_state:
        st.session_state.detection_log = []

    detector = st.session_state.detector
    viz = st.session_state.visualizer

    # â”€â”€ Header â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    st.markdown('<h1 class="main-header">ğŸ¯ VisionTrack</h1>', unsafe_allow_html=True)
    st.markdown('<p class="sub-header">Real-Time Object Detection & Multi-Object Tracking</p>', unsafe_allow_html=True)

    # â”€â”€ Sidebar â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    with st.sidebar:
        st.markdown("### âš™ï¸ Configuration")

        st.markdown("**Model**")
        conf_threshold = st.slider("Confidence", 0.1, 1.0, 0.5, 0.05)
        input_size = st.select_slider("Resolution", [320, 416, 640], value=640)

        st.markdown("**Tracking**")
        enable_tracking = st.checkbox("Enable Tracking", value=True)
        show_trails = st.checkbox("Show Trails", value=True)

        st.markdown("**Display**")
        show_overlay = st.checkbox("Show HUD Overlay", value=True)

        st.markdown("---")
        st.markdown(
            '<div style="text-align:center;color:#6B7280;font-size:0.8rem;">'
            'VisionTrack v2.0<br>YOLOv8 Â· Streamlit</div>',
            unsafe_allow_html=True,
        )

    # â”€â”€ Tabs â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    tab_detect, tab_analytics, tab_about = st.tabs(["ğŸ¥ Detection", "ğŸ“Š Analytics", "â„¹ï¸ About"])

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # TAB 1: DETECTION
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    with tab_detect:
        # Source selector
        is_cloud = os.environ.get("STREAMLIT_SERVER_HEADLESS") == "true" or os.environ.get("SPACE_ID")
        source_options = ["ğŸ“¹ Upload Video", "ğŸ–¼ï¸ Upload Image"]
        if not is_cloud:
            source_options.append("ğŸ“· Webcam (Local)")
        source = st.radio("Input Source", source_options, horizontal=True)

        # Metric placeholders
        mc1, mc2, mc3, mc4 = st.columns(4)
        fps_ph = mc1.empty()
        det_ph = mc2.empty()
        trk_ph = mc3.empty()
        frm_ph = mc4.empty()

        # Default metric cards
        fps_ph.markdown('<div class="metric-card"><div class="metric-value">â€”</div><div class="metric-label">FPS</div></div>', unsafe_allow_html=True)
        det_ph.markdown('<div class="metric-card"><div class="metric-value">â€”</div><div class="metric-label">Detections</div></div>', unsafe_allow_html=True)
        trk_ph.markdown('<div class="metric-card"><div class="metric-value">â€”</div><div class="metric-label">Active Tracks</div></div>', unsafe_allow_html=True)
        frm_ph.markdown('<div class="metric-card"><div class="metric-value">â€”</div><div class="metric-label">Frame</div></div>', unsafe_allow_html=True)

        video_placeholder = st.empty()
        status_placeholder = st.empty()

        # â”€â”€ VIDEO UPLOAD â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        if source == "ğŸ“¹ Upload Video":
            uploaded = st.file_uploader("Upload a video", type=["mp4", "avi", "mov", "mkv"],
                                        help="Max 200 MB Â· Supported: MP4, AVI, MOV, MKV")
            if uploaded is not None:
                if st.button("â–¶ Start Detection", use_container_width=True, type="primary"):
                    tfile = tempfile.NamedTemporaryFile(delete=False, suffix='.mp4')
                    tfile.write(uploaded.read())
                    tfile.flush()
                    tfile.close()

                    progress_bar = st.progress(0, text="Starting...")
                    log = process_video(
                        tfile.name, detector, viz,
                        conf_threshold, input_size,
                        enable_tracking, show_trails, show_overlay,
                        video_placeholder, fps_ph, det_ph, trk_ph, frm_ph,
                        status_placeholder, progress_bar,
                    )
                    st.session_state.detection_log = log
                    os.unlink(tfile.name)
                    status_placeholder.success(f"âœ… Done â€” processed {len(log)} frames!")
            else:
                video_placeholder.info("ğŸ“¤ Upload a video file above to begin detection.")

        # â”€â”€ IMAGE UPLOAD â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        elif source == "ğŸ–¼ï¸ Upload Image":
            uploaded_img = st.file_uploader("Upload an image", type=["jpg", "jpeg", "png", "bmp", "webp"],
                                            help="Supported: JPG, PNG, BMP, WebP")
            if uploaded_img is not None:
                if st.button("ğŸ” Detect Objects", use_container_width=True, type="primary"):
                    status_placeholder.info("â³ Loading model...")
                    log = process_image(
                        uploaded_img, detector, viz,
                        conf_threshold, input_size,
                        enable_tracking, show_overlay,
                        video_placeholder, fps_ph, det_ph, trk_ph, frm_ph,
                    )
                    st.session_state.detection_log = log
                    status_placeholder.success("âœ… Detection complete!")
            else:
                video_placeholder.info("ğŸ–¼ï¸ Upload an image above to detect objects.")

        # â”€â”€ WEBCAM â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        elif source == "ğŸ“· Webcam (Local)":
            st.warning("âš ï¸ Webcam is only available when running locally, not on Streamlit Cloud.")
            stop_container = st.empty()
            if st.button("ğŸ“· Start Webcam", use_container_width=True, type="primary"):
                log = process_webcam(
                    detector, viz,
                    conf_threshold, input_size,
                    enable_tracking, show_trails, show_overlay,
                    video_placeholder, fps_ph, det_ph, trk_ph, frm_ph,
                    status_placeholder, stop_container,
                )
                st.session_state.detection_log = log
                status_placeholder.success(f"âœ… Webcam stopped â€” captured {len(log)} frames.")

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # TAB 2: ANALYTICS
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    with tab_analytics:
        st.markdown("### ğŸ“Š Detection Analytics")

        if st.session_state.detection_log:
            import pandas as pd
            df = pd.DataFrame(st.session_state.detection_log)

            col_a, col_b = st.columns(2)
            with col_a:
                st.markdown("**Detections per Frame**")
                st.area_chart(df.set_index('frame')['detections'], color="#7C3AED")
            with col_b:
                st.markdown("**Active Tracks per Frame**")
                st.area_chart(df.set_index('frame')['tracks'], color="#3B82F6")

            st.markdown("**FPS Over Time**")
            st.line_chart(df.set_index('frame')['fps'], color="#10B981")

            st.markdown("**Summary**")
            sc1, sc2, sc3, sc4 = st.columns(4)
            sc1.metric("Total Frames", len(df))
            sc2.metric("Avg Detections", f"{df['detections'].mean():.1f}")
            sc3.metric("Max Tracks", int(df['tracks'].max()))
            sc4.metric("Avg FPS", f"{df['fps'].mean():.1f}")

            if st.button("ğŸ—‘ï¸ Clear Analytics", use_container_width=True):
                st.session_state.detection_log = []
                st.rerun()
        else:
            st.info("ğŸ“ˆ Analytics will appear after you process a video or image in the Detection tab.")

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # TAB 3: ABOUT
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    with tab_about:
        st.markdown("### About VisionTrack")
        st.markdown(
            "A real-time object detection and multi-object tracking system "
            "built with **YOLOv8** and **Streamlit**."
        )

        st.markdown("#### âœ¨ Features")
        fc1, fc2, fc3 = st.columns(3)
        with fc1:
            st.markdown("""
            <div class="feature-card">
            <h4>ğŸ¯ YOLOv8 Detection</h4>
            <p>92%+ accuracy on 80 COCO classes with real-time inference.</p>
            </div>
            """, unsafe_allow_html=True)
        with fc2:
            st.markdown("""
            <div class="feature-card">
            <h4>ğŸ”— Multi-Object Tracking</h4>
            <p>IOU-based tracker with trajectory visualization and ID persistence.</p>
            </div>
            """, unsafe_allow_html=True)
        with fc3:
            st.markdown("""
            <div class="feature-card">
            <h4>ğŸ“Š Live Analytics</h4>
            <p>Real-time FPS, detection counts, and post-processing charts.</p>
            </div>
            """, unsafe_allow_html=True)

        st.markdown("#### ğŸ› ï¸ Technology Stack")
        st.markdown("""
        <div style="margin:1rem 0">
        <span class="tech-badge">YOLOv8</span>
        <span class="tech-badge">Streamlit</span>
        <span class="tech-badge">OpenCV</span>
        <span class="tech-badge">NumPy</span>
        <span class="tech-badge">PyTorch</span>
        <span class="tech-badge">Python 3.11+</span>
        </div>
        """, unsafe_allow_html=True)

        st.markdown("#### ğŸ“Š Performance")
        perf_data = {
            "Metric": ["FPS", "Accuracy", "Model Size", "Classes"],
            "Value": ["40+ on modern hardware", "92%+ (COCO)", "6.2 MB (auto-downloads)", "80 COCO categories"],
        }
        st.table(perf_data)

        st.markdown(
            '<div class="footer">Built with â¤ï¸ using YOLOv8 Â· Streamlit Â· OpenCV</div>',
            unsafe_allow_html=True,
        )


if __name__ == "__main__":
    main()
