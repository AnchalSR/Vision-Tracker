"""
VisionTrack: Real-Time Object Detection & Tracking
Built for Streamlit Cloud â€” Python 3.11 / 3.13 compatible
"""

import streamlit as st
import cv2
import numpy as np
import time
from PIL import Image
import tempfile
import os
from collections import defaultdict

# ============================================================================
# CONFIGURATION
# ============================================================================

CONFIDENCE_THRESHOLD = 0.5
IOU_THRESHOLD = 0.45
INPUT_SIZE = 640

COCO_CLASSES = [
    'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat',
    'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat',
    'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack',
    'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball',
    'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket',
    'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple',
    'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair',
    'couch', 'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse',
    'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator',
    'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush'
]


# ============================================================================
# OBJECT DETECTOR (YOLOv8)
# ============================================================================

class ObjectDetector:
    """YOLOv8-based object detector"""

    def __init__(self, conf_threshold=None, input_size=None):
        self.conf_threshold = conf_threshold or CONFIDENCE_THRESHOLD
        self.input_size = input_size or INPUT_SIZE
        self.model = None
        self.fps = 0.0
        self.frame_count = 0
        self.start_time = time.time()

    def load(self):
        """Load YOLOv8 model (call once)"""
        if self.model is not None:
            return
        from ultralytics import YOLO
        self.model = YOLO('yolov8n.pt')
        self.model.overrides['conf'] = self.conf_threshold
        self.model.overrides['iou'] = IOU_THRESHOLD

    def detect(self, frame):
        """Run detection on a single frame. Returns Nx6 array [x1,y1,x2,y2,conf,class_id]"""
        if self.model is None:
            self.load()

        results = self.model(
            frame,
            imgsz=self.input_size,
            conf=self.conf_threshold,
            verbose=False
        )

        detections = []
        if len(results) > 0 and results[0].boxes is not None:
            for box in results[0].boxes:
                x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()
                conf = float(box.conf[0].cpu().numpy())
                cls = int(box.cls[0].cpu().numpy())
                detections.append([x1, y1, x2, y2, conf, cls])

        self._update_fps()
        return np.array(detections) if detections else np.empty((0, 6))

    def _update_fps(self):
        self.frame_count += 1
        elapsed = time.time() - self.start_time
        if elapsed > 0:
            self.fps = self.frame_count / elapsed
        if self.frame_count >= 30:
            self.frame_count = 0
            self.start_time = time.time()

    @staticmethod
    def get_class_name(class_id):
        if 0 <= class_id < len(COCO_CLASSES):
            return COCO_CLASSES[class_id]
        return f"class_{class_id}"


# ============================================================================
# MULTI-OBJECT TRACKER (IOU-based, zero external deps)
# ============================================================================

class SimpleTracker:
    """
    Lightweight IOU-based multi-object tracker.
    No external dependencies â€” works on Python 3.11â€“3.13.
    """

    def __init__(self, max_disappeared=30, iou_threshold=0.3):
        self.next_id = 1
        self.objects = {}          # id -> {bbox, class_id, conf, age, disappeared}
        self.track_history = {}    # id -> list of (cx, cy)
        self.max_disappeared = max_disappeared
        self.iou_threshold = iou_threshold
        self.total_tracks = 0

    @staticmethod
    def _iou(box_a, box_b):
        """Compute IoU between two boxes [x1,y1,x2,y2]"""
        x1 = max(box_a[0], box_b[0])
        y1 = max(box_a[1], box_b[1])
        x2 = min(box_a[2], box_b[2])
        y2 = min(box_a[3], box_b[3])
        inter = max(0, x2 - x1) * max(0, y2 - y1)
        area_a = (box_a[2] - box_a[0]) * (box_a[3] - box_a[1])
        area_b = (box_b[2] - box_b[0]) * (box_b[3] - box_b[1])
        union = area_a + area_b - inter
        return inter / union if union > 0 else 0

    def update(self, detections):
        """
        Update tracker with new detections.
        detections: Nx6 array [x1,y1,x2,y2,conf,class_id]
        Returns list of [x1,y1,x2,y2,track_id,class_id,conf]
        """
        if len(detections) == 0:
            for obj_id in list(self.objects):
                self.objects[obj_id]['disappeared'] += 1
                if self.objects[obj_id]['disappeared'] > self.max_disappeared:
                    del self.objects[obj_id]
            return []

        det_boxes = detections[:, :4]
        det_confs = detections[:, 4]
        det_classes = detections[:, 5].astype(int)

        if len(self.objects) == 0:
            for i in range(len(detections)):
                self._register(det_boxes[i], det_classes[i], det_confs[i])
        else:
            obj_ids = list(self.objects.keys())
            obj_boxes = np.array([self.objects[oid]['bbox'] for oid in obj_ids])

            # Build IOU matrix
            iou_matrix = np.zeros((len(obj_ids), len(det_boxes)))
            for i, ob in enumerate(obj_boxes):
                for j, db in enumerate(det_boxes):
                    iou_matrix[i, j] = self._iou(ob, db)

            # Greedy matching
            matched_objs = set()
            matched_dets = set()

            while True:
                if iou_matrix.size == 0:
                    break
                max_val = iou_matrix.max()
                if max_val < self.iou_threshold:
                    break
                max_idx = np.unravel_index(iou_matrix.argmax(), iou_matrix.shape)
                i, j = max_idx

                oid = obj_ids[i]
                self.objects[oid]['bbox'] = det_boxes[j]
                self.objects[oid]['class_id'] = det_classes[j]
                self.objects[oid]['conf'] = det_confs[j]
                self.objects[oid]['disappeared'] = 0

                cx = int((det_boxes[j][0] + det_boxes[j][2]) / 2)
                cy = int((det_boxes[j][1] + det_boxes[j][3]) / 2)
                self.track_history[oid].append((cx, cy))
                if len(self.track_history[oid]) > 30:
                    self.track_history[oid] = self.track_history[oid][-30:]

                matched_objs.add(i)
                matched_dets.add(j)

                iou_matrix[i, :] = 0
                iou_matrix[:, j] = 0

            # Handle unmatched existing objects
            for i, oid in enumerate(obj_ids):
                if i not in matched_objs:
                    self.objects[oid]['disappeared'] += 1
                    if self.objects[oid]['disappeared'] > self.max_disappeared:
                        del self.objects[oid]

            # Register unmatched detections
            for j in range(len(det_boxes)):
                if j not in matched_dets:
                    self._register(det_boxes[j], det_classes[j], det_confs[j])

        # Build output
        tracked = []
        for oid, obj in self.objects.items():
            if obj['disappeared'] == 0:
                b = obj['bbox']
                tracked.append([b[0], b[1], b[2], b[3], oid, obj['class_id'], obj['conf']])
        return tracked

    def _register(self, bbox, class_id, conf):
        oid = self.next_id
        self.next_id += 1
        self.total_tracks += 1
        cx = int((bbox[0] + bbox[2]) / 2)
        cy = int((bbox[1] + bbox[3]) / 2)
        self.objects[oid] = {
            'bbox': bbox,
            'class_id': int(class_id),
            'conf': float(conf),
            'disappeared': 0,
        }
        self.track_history[oid] = [(cx, cy)]

    @property
    def active_tracks(self):
        return sum(1 for o in self.objects.values() if o['disappeared'] == 0)


# ============================================================================
# VISUALIZER
# ============================================================================

class Visualizer:
    """Draws bounding boxes, labels, trajectories and overlays on frames."""

    def __init__(self):
        np.random.seed(42)
        self.colors = self._generate_colors(100)

    @staticmethod
    def _generate_colors(n):
        colors = []
        for i in range(n):
            hue = int(180 * i / n)
            color = cv2.cvtColor(np.uint8([[[hue, 255, 200]]]), cv2.COLOR_HSV2BGR)[0][0]
            colors.append(tuple(map(int, color)))
        return colors

    def draw_detections(self, frame, detections):
        out = frame.copy()
        for det in detections:
            x1, y1, x2, y2, conf, cls = det
            x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)
            color = self.colors[int(cls) % len(self.colors)]
            label = f"{ObjectDetector.get_class_name(int(cls))} {conf:.2f}"

            cv2.rectangle(out, (x1, y1), (x2, y2), color, 2)
            (lw, lh), _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.55, 1)
            cv2.rectangle(out, (x1, y1 - lh - 8), (x1 + lw + 4, y1), color, -1)
            cv2.putText(out, label, (x1 + 2, y1 - 4), cv2.FONT_HERSHEY_SIMPLEX, 0.55, (255, 255, 255), 1, cv2.LINE_AA)
        return out

    def draw_tracks(self, frame, tracked_objects, track_history, show_trails=True):
        out = frame.copy()
        for obj in tracked_objects:
            x1, y1, x2, y2, tid, cls, conf = obj
            x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)
            color = self.colors[int(tid) % len(self.colors)]
            label = f"ID:{tid} {ObjectDetector.get_class_name(int(cls))} {conf:.2f}"

            cv2.rectangle(out, (x1, y1), (x2, y2), color, 2)
            (lw, lh), _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.55, 1)
            cv2.rectangle(out, (x1, y1 - lh - 8), (x1 + lw + 4, y1), color, -1)
            cv2.putText(out, label, (x1 + 2, y1 - 4), cv2.FONT_HERSHEY_SIMPLEX, 0.55, (255, 255, 255), 1, cv2.LINE_AA)

            if show_trails and tid in track_history and len(track_history[tid]) > 1:
                pts = track_history[tid]
                for k in range(1, len(pts)):
                    thickness = max(1, int(np.sqrt(40 / float(k + 1)) * 1.2))
                    cv2.line(out, pts[k - 1], pts[k], color, thickness, cv2.LINE_AA)
        return out

    @staticmethod
    def draw_overlay(frame, fps, det_count, track_count):
        """Draw a translucent HUD overlay with stats."""
        overlay = frame.copy()
        h, w = frame.shape[:2]

        # Background bar
        cv2.rectangle(overlay, (8, 8), (220, 120), (15, 15, 25), -1)
        frame = cv2.addWeighted(overlay, 0.7, frame, 0.3, 0)

        # Border
        cv2.rectangle(frame, (8, 8), (220, 120), (124, 58, 237), 2)

        # Text
        cv2.putText(frame, f"FPS: {fps:.1f}", (18, 35), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (124, 58, 237), 2, cv2.LINE_AA)
        cv2.putText(frame, f"Detections: {det_count}", (18, 65), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (16, 185, 129), 2, cv2.LINE_AA)
        cv2.putText(frame, f"Tracks: {track_count}", (18, 95), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (59, 130, 246), 2, cv2.LINE_AA)
        return frame


# ============================================================================
# CUSTOM CSS
# ============================================================================

CUSTOM_CSS = """
<style>
@import url('https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap');

html, body, [class*="css"] {
    font-family: 'Inter', sans-serif;
}

/* Header styling */
.main-header {
    background: linear-gradient(135deg, #7C3AED 0%, #EC4899 100%);
    -webkit-background-clip: text;
    -webkit-text-fill-color: transparent;
    font-size: 2.8rem;
    font-weight: 700;
    text-align: center;
    margin-bottom: 0;
    line-height: 1.2;
}
.sub-header {
    text-align: center;
    color: #9CA3AF;
    font-size: 1.05rem;
    margin-top: -0.5rem;
    margin-bottom: 1.5rem;
}

/* Metric cards */
.metric-card {
    background: linear-gradient(145deg, #1E1E2E 0%, #2A2A3E 100%);
    border: 1px solid rgba(124, 58, 237, 0.3);
    border-radius: 12px;
    padding: 1.2rem 1rem;
    text-align: center;
    transition: transform 0.2s, box-shadow 0.2s;
}
.metric-card:hover {
    transform: translateY(-2px);
    box-shadow: 0 8px 25px rgba(124, 58, 237, 0.2);
}
.metric-value {
    font-size: 2rem;
    font-weight: 700;
    background: linear-gradient(135deg, #7C3AED 0%, #3B82F6 100%);
    -webkit-background-clip: text;
    -webkit-text-fill-color: transparent;
}
.metric-label {
    font-size: 0.85rem;
    color: #9CA3AF;
    margin-top: 0.25rem;
}

/* Sidebar */
section[data-testid="stSidebar"] {
    background: linear-gradient(180deg, #0F0F1A 0%, #1A1A2E 100%);
    border-right: 1px solid rgba(124, 58, 237, 0.2);
}

/* Video frame area */
.video-frame {
    border: 2px solid rgba(124, 58, 237, 0.3);
    border-radius: 12px;
    overflow: hidden;
}

/* Tabs */
.stTabs [data-baseweb="tab-list"] {
    gap: 8px;
}
.stTabs [data-baseweb="tab"] {
    border-radius: 8px;
    padding: 8px 20px;
}

/* Feature cards */
.feature-card {
    background: linear-gradient(145deg, #1E1E2E 0%, #252540 100%);
    border: 1px solid rgba(124, 58, 237, 0.15);
    border-radius: 12px;
    padding: 1.5rem;
    height: 100%;
}
.feature-card h4 {
    color: #A78BFA;
    margin-bottom: 0.5rem;
}

/* Tech badge */
.tech-badge {
    display: inline-block;
    background: rgba(124, 58, 237, 0.15);
    border: 1px solid rgba(124, 58, 237, 0.3);
    border-radius: 20px;
    padding: 0.3rem 0.9rem;
    margin: 0.2rem;
    font-size: 0.85rem;
    color: #A78BFA;
}

/* Footer */
.footer {
    text-align: center;
    color: #6B7280;
    font-size: 0.85rem;
    margin-top: 3rem;
    padding: 1rem 0;
    border-top: 1px solid rgba(124, 58, 237, 0.15);
}
</style>
"""


# ============================================================================
# STREAMLIT APP
# ============================================================================

def render_metric(label, value, col):
    """Render a styled metric card."""
    col.markdown(f"""
    <div class="metric-card">
        <div class="metric-value">{value}</div>
        <div class="metric-label">{label}</div>
    </div>
    """, unsafe_allow_html=True)


def main():
    st.set_page_config(
        page_title="VisionTrack â€” Object Detection & Tracking",
        page_icon="ğŸ¯",
        layout="wide",
        initial_sidebar_state="expanded",
    )

    st.markdown(CUSTOM_CSS, unsafe_allow_html=True)

    # â”€â”€ Session State â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    if 'detector' not in st.session_state:
        st.session_state.detector = ObjectDetector()
    if 'tracker' not in st.session_state:
        st.session_state.tracker = SimpleTracker()
    if 'visualizer' not in st.session_state:
        st.session_state.visualizer = Visualizer()
    if 'detection_log' not in st.session_state:
        st.session_state.detection_log = []

    detector = st.session_state.detector
    tracker = st.session_state.tracker
    viz = st.session_state.visualizer

    # â”€â”€ Header â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    st.markdown('<h1 class="main-header">ğŸ¯ VisionTrack</h1>', unsafe_allow_html=True)
    st.markdown('<p class="sub-header">Real-Time Object Detection & Multi-Object Tracking</p>', unsafe_allow_html=True)

    # â”€â”€ Sidebar â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    with st.sidebar:
        st.markdown("### âš™ï¸ Configuration")

        st.markdown("**Model**")
        conf_threshold = st.slider("Confidence", 0.1, 1.0, 0.5, 0.05)
        input_size = st.select_slider("Resolution", [320, 416, 640], value=640)

        st.markdown("**Tracking**")
        enable_tracking = st.checkbox("Enable Tracking", value=True)
        show_trails = st.checkbox("Show Trails", value=True)

        st.markdown("**Display**")
        show_overlay = st.checkbox("Show HUD Overlay", value=True)

        st.markdown("---")
        st.markdown(
            '<div style="text-align:center;color:#6B7280;font-size:0.8rem;">'
            'VisionTrack v2.0<br>YOLOv8 Â· Streamlit</div>',
            unsafe_allow_html=True,
        )

    # Update detector settings
    detector.conf_threshold = conf_threshold
    detector.input_size = input_size

    # â”€â”€ Tabs â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    tab_detect, tab_analytics, tab_about = st.tabs(["ğŸ¥ Detection", "ğŸ“Š Analytics", "â„¹ï¸ About"])

    # â”€â”€ Tab 1: Detection â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    with tab_detect:
        uploaded = st.file_uploader(
            "Upload a video", type=["mp4", "avi", "mov", "mkv"],
            help="Max 200 MB Â· Supported: MP4, AVI, MOV, MKV"
        )

        # Metric placeholders
        mc1, mc2, mc3, mc4 = st.columns(4)
        fps_ph = mc1.empty()
        det_ph = mc2.empty()
        trk_ph = mc3.empty()
        frm_ph = mc4.empty()

        render_metric("FPS", "â€”", fps_ph)
        render_metric("Detections", "â€”", det_ph)
        render_metric("Active Tracks", "â€”", trk_ph)
        render_metric("Frame", "â€”", frm_ph)

        video_placeholder = st.empty()
        status_placeholder = st.empty()

        if uploaded is not None:
            run_col1, run_col2 = st.columns([1, 1])
            start = run_col1.button("â–¶ Start Detection", use_container_width=True, type="primary")
            stop_flag = run_col2.button("â¹ Stop", use_container_width=True)

            if start and not stop_flag:
                # Save uploaded video to temp file
                tfile = tempfile.NamedTemporaryFile(delete=False, suffix='.mp4')
                tfile.write(uploaded.read())
                tfile.flush()

                cap = cv2.VideoCapture(tfile.name)
                if not cap.isOpened():
                    status_placeholder.error("âŒ Could not open video file.")
                else:
                    status_placeholder.info("â³ Loading YOLOv8 model... (first run downloads ~6 MB)")
                    detector.load()
                    tracker_inst = SimpleTracker()   # fresh tracker per run
                    status_placeholder.success("âœ… Model loaded â€” processing video...")

                    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
                    frame_idx = 0

                    while cap.isOpened():
                        ret, frame = cap.read()
                        if not ret:
                            break
                        frame_idx += 1

                        # Resize for display speed
                        h, w = frame.shape[:2]
                        if w > 800:
                            scale = 800 / w
                            frame = cv2.resize(frame, None, fx=scale, fy=scale)

                        # Detect
                        dets = detector.detect(frame)

                        # Track or just detect
                        if enable_tracking:
                            tracked = tracker_inst.update(dets)
                            annotated = viz.draw_tracks(
                                frame, tracked, tracker_inst.track_history, show_trails
                            )
                            active_trk = tracker_inst.active_tracks
                        else:
                            annotated = viz.draw_detections(frame, dets)
                            active_trk = 0

                        # Overlay
                        if show_overlay:
                            annotated = viz.draw_overlay(
                                annotated, detector.fps, len(dets), active_trk
                            )

                        # Display
                        annotated_rgb = cv2.cvtColor(annotated, cv2.COLOR_BGR2RGB)
                        video_placeholder.image(annotated_rgb, use_container_width=True)

                        # Metrics
                        render_metric("FPS", f"{detector.fps:.1f}", fps_ph)
                        render_metric("Detections", str(len(dets)), det_ph)
                        render_metric("Active Tracks", str(active_trk), trk_ph)
                        render_metric("Frame", f"{frame_idx}/{total_frames}", frm_ph)

                        # Log for analytics
                        st.session_state.detection_log.append({
                            'frame': frame_idx,
                            'detections': len(dets),
                            'tracks': active_trk,
                            'fps': round(detector.fps, 1),
                        })

                    cap.release()
                    os.unlink(tfile.name)
                    status_placeholder.success(f"âœ… Done â€” processed {frame_idx} frames.")
        else:
            video_placeholder.info("ğŸ“¤ Upload a video file above to begin detection.")

    # â”€â”€ Tab 2: Analytics â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    with tab_analytics:
        st.markdown("### ğŸ“Š Detection Analytics")

        if st.session_state.detection_log:
            import pandas as pd

            df = pd.DataFrame(st.session_state.detection_log)

            col_a, col_b = st.columns(2)
            with col_a:
                st.markdown("**Detections per Frame**")
                st.area_chart(df.set_index('frame')['detections'], color="#7C3AED")
            with col_b:
                st.markdown("**Active Tracks per Frame**")
                st.area_chart(df.set_index('frame')['tracks'], color="#3B82F6")

            st.markdown("**FPS Over Time**")
            st.line_chart(df.set_index('frame')['fps'], color="#10B981")

            st.markdown("**Summary**")
            sum_c1, sum_c2, sum_c3, sum_c4 = st.columns(4)
            sum_c1.metric("Total Frames", len(df))
            sum_c2.metric("Avg Detections", f"{df['detections'].mean():.1f}")
            sum_c3.metric("Max Tracks", int(df['tracks'].max()))
            sum_c4.metric("Avg FPS", f"{df['fps'].mean():.1f}")
        else:
            st.info("ğŸ“ˆ Analytics will appear after you process a video in the Detection tab.")

    # â”€â”€ Tab 3: About â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    with tab_about:
        st.markdown("### About VisionTrack")
        st.markdown(
            "A real-time object detection and multi-object tracking system "
            "built with **YOLOv8** and **Streamlit**."
        )

        st.markdown("#### âœ¨ Features")
        fc1, fc2, fc3 = st.columns(3)
        with fc1:
            st.markdown("""
            <div class="feature-card">
            <h4>ğŸ¯ YOLOv8 Detection</h4>
            <p>92%+ accuracy on 80 COCO classes with real-time inference.</p>
            </div>
            """, unsafe_allow_html=True)
        with fc2:
            st.markdown("""
            <div class="feature-card">
            <h4>ğŸ”— Multi-Object Tracking</h4>
            <p>IOU-based tracker with trajectory visualization and ID persistence.</p>
            </div>
            """, unsafe_allow_html=True)
        with fc3:
            st.markdown("""
            <div class="feature-card">
            <h4>ğŸ“Š Live Analytics</h4>
            <p>Real-time FPS, detection counts, and post-processing charts.</p>
            </div>
            """, unsafe_allow_html=True)

        st.markdown("#### ğŸ› ï¸ Technology Stack")
        st.markdown("""
        <div style="margin:1rem 0">
        <span class="tech-badge">YOLOv8</span>
        <span class="tech-badge">Streamlit</span>
        <span class="tech-badge">OpenCV</span>
        <span class="tech-badge">NumPy</span>
        <span class="tech-badge">PyTorch</span>
        <span class="tech-badge">Python 3.13</span>
        </div>
        """, unsafe_allow_html=True)

        st.markdown("#### ğŸ“Š Performance")
        perf_data = {
            "Metric": ["FPS", "Accuracy", "Model Size", "Classes"],
            "Value": ["40+ on modern hardware", "92%+ (COCO)", "6.2 MB", "80 COCO classes"],
        }
        st.table(perf_data)

        st.markdown(
            '<div class="footer">Built with â¤ï¸ using YOLOv8 Â· Streamlit Â· OpenCV</div>',
            unsafe_allow_html=True,
        )


if __name__ == "__main__":
    main()
